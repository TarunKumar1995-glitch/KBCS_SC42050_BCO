{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from tqdm import trange\n",
    "import numpy as np\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch as T\n",
    "import torch.nn as nn\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(111,) (8,)\n",
      "Ep 1: 6.22\n",
      "Ep 2: -37.62\n",
      "Ep 3: -47.95\n",
      "Ep 4: 3.09\n",
      "Ep 5: 1.93\n",
      "Ep 6: -287.07\n",
      "Ep 7: -10.75\n",
      "Ep 8: -57.32\n",
      "Ep 9: -23.57\n",
      "Ep 10: 0.54\n",
      "Ep 11: -5.81\n",
      "Ep 12: -39.23\n",
      "Ep 13: -334.52\n",
      "Ep 14: -294.70\n",
      "Ep 15: -8.60\n",
      "Ep 16: -33.87\n",
      "Ep 17: -27.03\n",
      "Ep 18: -68.67\n",
      "Ep 19: 4.27\n",
      "Ep 20: -328.60\n",
      "-79.46332320224306\n",
      "120.7883100609068\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "\n",
    "env = gym.make('Ant-v2')\n",
    "print(env.observation_space.shape, env.action_space.shape)\n",
    "\n",
    "rews = 0\n",
    "temp = -54\n",
    "var = 0\n",
    "for i in range(20):\n",
    "    env.reset()\n",
    "    rew = 0\n",
    "    \n",
    "    while True:\n",
    "        _, r, done, _ = env.step(env.action_space.sample())\n",
    "        \n",
    "        rew += r\n",
    "        \n",
    "        if done==True:\n",
    "            print('Ep %d: %.2f' % (i+1, rew))\n",
    "            rews += rew\n",
    "            var += (rew-temp)**2\n",
    "            break\n",
    "rews = rews/20\n",
    "var = (var/20)**0.5\n",
    "print(rews)\n",
    "print(var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class BCO(nn.Module):\n",
    "    def __init__(self, env, policy='mlp'):\n",
    "        super(BCO, self).__init__()\n",
    "        \n",
    "        self.policy = policy\n",
    "        self.act_n = env.action_space.shape[0]\n",
    "        \n",
    "        if self.policy=='mlp':\n",
    "            self.obs_n = env.observation_space.shape[0]\n",
    "            self.inv = nn.Sequential(*[nn.Linear(self.obs_n*2, 100), nn.LeakyReLU(), \n",
    "                                       nn.Linear(100, 100), nn.LeakyReLU(), \n",
    "                                       nn.Linear(100, self.act_n)])\n",
    "            self.pol = nn.Sequential(*[nn.Linear(self.obs_n, 32), nn.LeakyReLU(), \n",
    "                                       nn.Linear(32, 32), nn.LeakyReLU(),  \n",
    "                                       nn.Linear(32, self.act_n)])\n",
    "        \n",
    "        elif self.policy=='cnn':\n",
    "            pass\n",
    "    \n",
    "    def pred_act(self, obs):\n",
    "        out = self.pol(obs)\n",
    "        \n",
    "        return out\n",
    "    \n",
    "    def pred_inv(self, obs1, obs2):\n",
    "        obs = T.cat([obs1, obs2], dim=1)\n",
    "        out = self.inv(obs)\n",
    "        \n",
    "        return out\n",
    "\n",
    "POLICY = 'mlp'\n",
    "model = BCO(env, policy=POLICY).cuda()\n",
    "model.load_state_dict(torch.load('Model/model_ant_ID_train_1.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class DS_Inv(Dataset):\n",
    "    def __init__(self, trajs):\n",
    "        self.dat = []\n",
    "        \n",
    "        for traj in trajs:\n",
    "            for dat in traj:\n",
    "                obs, act, new_obs = dat\n",
    "                \n",
    "                self.dat.append([obs, new_obs, act])\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.dat)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        obs, new_obs, act = self.dat[idx]\n",
    "        \n",
    "        return obs, new_obs, act\n",
    "\n",
    "class DS_Policy(Dataset):\n",
    "    def __init__(self, traj):\n",
    "        self.dat = []\n",
    "        \n",
    "        for dat in traj:\n",
    "            obs, act = dat\n",
    "                \n",
    "            self.dat.append([obs, act])\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.dat)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        obs, act = self.dat[idx]\n",
    "        \n",
    "        return obs, act"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "trajs_demo = pickle.load(open('Demo/demo_ant.pkl', 'rb'))\n",
    "print(len(trajs_demo))\n",
    "ld_demo = DataLoader(DS_Inv(trajs_demo), batch_size=50)\n",
    "\n",
    "print(len(ld_demo))\n",
    "for obs1, obs2,act in ld_demo:\n",
    "    print(obs1.shape, obs2.shape, act.shape)\n",
    "    print(act[0])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_func = nn.MSELoss().cuda()\n",
    "optim = T.optim.Adam(model.parameters(), lr=5e-4)\n",
    "\n",
    "alpha = 0\n",
    "M = 500000\n",
    "\n",
    "EPS = 0.9\n",
    "DECAY = 2e-3\n",
    "random_seed = 42\n",
    "epochs = 1000\n",
    "patience = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_valid_loader(dataset, batch_size, validation_split, shuffle_dataset):\n",
    "    dataset_size = len(dataset)\n",
    "    indices = list(range(dataset_size))\n",
    "    split = int(np.floor(validation_split * dataset_size))\n",
    "    if shuffle_dataset :\n",
    "        np.random.seed(random_seed)\n",
    "        np.random.shuffle(indices)\n",
    "    train_indices, val_indices = indices[split:], indices[:split]\n",
    "    train_sampler = SubsetRandomSampler(train_indices)\n",
    "    valid_sampler = SubsetRandomSampler(val_indices)\n",
    "    train_loader = torch.utils.data.DataLoader(dataset,batch_size=batch_size,\n",
    "                                               sampler=train_sampler)\n",
    "    validation_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size,\n",
    "                                                    sampler=valid_sampler)\n",
    "    return train_loader, validation_loader\n",
    "\n",
    "def train_NN(train_loader, NN):\n",
    "    \n",
    "    with tqdm(train_loader, desc='Training',  disable = True, position=0, leave=True) as TQ:\n",
    "        ls_ep = 0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        \n",
    "        if (NN == 'inv'):\n",
    "            for obs1, obs2, act in TQ:\n",
    "                out = model.pred_inv(obs1.float().cuda(), obs2.float().cuda())\n",
    "                ls_bh = loss_func(out, act.cuda())\n",
    "                \n",
    "                optim.zero_grad()\n",
    "                ls_bh.backward()\n",
    "                optim.step()\n",
    "\n",
    "                ls_bh = ls_bh.cpu().detach().numpy()\n",
    "                TQ.set_postfix(loss_policy='%.3f' % (ls_bh))\n",
    "                ls_ep += ls_bh\n",
    "                total += obs1.shape[0]\n",
    "                \n",
    "        elif(NN == 'pred'):\n",
    "            for obs, act in TQ:\n",
    "                out = model.pred_act(obs.float().cuda())\n",
    "                ls_bh = loss_func(out, act.cuda())\n",
    "\n",
    "                optim.zero_grad()\n",
    "                ls_bh.backward()\n",
    "                optim.step()\n",
    "\n",
    "                ls_bh = ls_bh.cpu().detach().numpy()\n",
    "                TQ.set_postfix(loss_policy='%.3f' % (ls_bh))\n",
    "                ls_ep += ls_bh\n",
    "                total += obs.shape[0]\n",
    "            \n",
    "        ls_ep /= len(TQ)\n",
    "        \n",
    "    return ls_ep\n",
    "\n",
    "def validate_NN(validation_loader, NN):\n",
    "    \n",
    "    with tqdm(validation_loader, desc='Validate', disable = True, position=0, leave=True) as TQ:\n",
    "        ls_val_ep = 0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        \n",
    "        if (NN == 'inv'):\n",
    "            for obs1, obs2, act in TQ:\n",
    "                out = model.pred_inv(obs1.float().cuda(), obs2.float().cuda())\n",
    "                ls_bh = loss_func(out, act.cuda())\n",
    "                ls_bh = ls_bh.cpu().detach().numpy()\n",
    "                TQ.set_postfix(loss_policy='%.3f' % (ls_bh))\n",
    "                ls_val_ep += ls_bh\n",
    "                total += obs1.shape[0]\n",
    "        elif (NN == 'pred'):\n",
    "            for obs, act in TQ:\n",
    "                out = model.pred_act(obs.float().cuda())\n",
    "                ls_bh = loss_func(out, act.cuda())\n",
    "                ls_bh = ls_bh.cpu().detach().numpy()\n",
    "                TQ.set_postfix(loss_policy='%.3f' % (ls_bh))\n",
    "                ls_val_ep += ls_bh\n",
    "                total += obs.shape[0]\n",
    "            \n",
    "        ls_val_ep /= len(TQ)\n",
    "        \n",
    "        return ls_val_ep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "trajs_inv = []\n",
    "tqdm_alpha = trange(alpha+1, position=0, desc='alpha:', leave=True)\n",
    "policy_best = 10\n",
    "policy_patience = 5\n",
    "policy_patience_cnt = 0\n",
    "\n",
    "for e in tqdm_alpha:\n",
    "    \n",
    "    # step1, generate inverse samples\n",
    "    if e==0:\n",
    "        trajs_inv = np.load('PreDemo_Interactions_Ant_5Lakh.npy',allow_pickle=True)\n",
    "    else:\n",
    "        tqdm_alpha.set_description(\"alpha: %i, Step1: Exploration\" % e,refresh=True)\n",
    "        time.sleep(1)\n",
    "        cnt = 0 #count\n",
    "        epn = 0 #Episode number\n",
    "\n",
    "        rews = 0 #Rewards\n",
    "\n",
    "        while True:\n",
    "            traj = []\n",
    "            rew = 0\n",
    "            N=0 \n",
    "            obs = env.reset()\n",
    "            while True:\n",
    "                inp = T.from_numpy(obs).view(((1, )+obs.shape)).float().cuda()\n",
    "                out = model.pred_act(inp).cpu().detach().numpy()\n",
    "                if e==0:\n",
    "                    act = env.action_space.sample()               \n",
    "                else:\n",
    "                    act = out[0]\n",
    "\n",
    "\n",
    "                new_obs, r, done, _ = env.step(act)\n",
    "\n",
    "                traj.append([obs, act, new_obs])\n",
    "                obs = new_obs\n",
    "                rew += r\n",
    "\n",
    "                cnt += 1\n",
    "                tqdm_alpha.set_description(\"alpha: %i, Step1: Exploration - %i\" % (e,cnt),refresh=True)\n",
    "                N+=1   \n",
    "                if done==True :\n",
    "                    rews += rew\n",
    "                    trajs_inv.append(traj)\n",
    "\n",
    "                    epn += 1\n",
    "\n",
    "                    break\n",
    "\n",
    "            if cnt >= M:\n",
    "                break\n",
    "\n",
    "        rews /= epn\n",
    "        tqdm_alpha.set_description(\"alpha: %i, step1: Exploration, Reward: %.2f\" % (e,rews),refresh=True)\n",
    "        time.sleep(1)\n",
    "      \n",
    "    \n",
    "    # step2, update inverse model\n",
    "\n",
    "    if e!=0:\n",
    "    \n",
    "#         ls_val_best = 0.025\n",
    "        ls_val_best = 1\n",
    "        patience_cnt = 0\n",
    "        tqdm_alpha.set_description(\"alpha: %i, Step2: Update Inverse Model\" % e,refresh=True)\n",
    "        time.sleep(1)\n",
    "        tqdm_epoch = trange(epochs, position=0, desc='Epoch:', leave=True)\n",
    "        for i in  tqdm_epoch:\n",
    "            dataset=DS_Inv(trajs_inv)\n",
    "            train_loader, validation_loader = train_valid_loader(dataset, batch_size=32, \n",
    "                                                                 validation_split=0.3,\n",
    "                                                                 shuffle_dataset=True)\n",
    "            \n",
    "            ls_ep = train_NN(train_loader, NN = 'inv')\n",
    "            ls_val_ep = validate_NN(validation_loader, NN = 'inv')\n",
    "            \n",
    "            tqdm_epoch.set_description(\"ID Model Update - Epoch: %i, val loss: %.3f\" % (i,ls_val_ep),refresh=True)\n",
    "            \n",
    "            if ls_val_ep < ls_val_best:\n",
    "                ls_val_best = ls_val_ep\n",
    "                patience_cnt = 0\n",
    "        \n",
    "            else:\n",
    "                patience_cnt += 1\n",
    "                if patience_cnt == patience:\n",
    "    #                 print(\"break\")\n",
    "                    break\n",
    "\n",
    "#             if ls_val_ep < ls_val_best:\n",
    "#                 break\n",
    "\n",
    "    \n",
    "#     T.save(model.state_dict(), 'Model/model_ant_ID_train_%d.pt' % (e+1))\n",
    "    \n",
    "    \n",
    "    # step3, predict actions for demo trajectories\n",
    "    traj_policy = []\n",
    "    tqdm_alpha.set_description(\"alpha: %i, Step3: Predict most probable actions for expert demos\" % e,refresh=True)\n",
    "    obs_cnt = 0\n",
    "    for obs1, obs2, _ in ld_demo:\n",
    "        out = model.pred_inv(obs1.float().cuda(), obs2.float().cuda())\n",
    "        obs = obs1.cpu().detach().numpy()\n",
    "        out = out.cpu().detach().numpy()\n",
    "        for i in range(len(obs1)):\n",
    "            traj_policy.append([obs[i], out[i]])\n",
    "        obs_cnt+=1\n",
    "        if obs_cnt==25:\n",
    "            break\n",
    "    \n",
    "#     pred_id_acts = np.asarray(traj_policy, dtype=object)\n",
    "#     np.save('Pred_acts_demo_obs_Ant_5Lakh.npy', pred_id_acts)\n",
    "\n",
    "    # step4, update policy via demo samples\n",
    "    ls_val_best = 5\n",
    "    patience_cnt = 0\n",
    "    tqdm_alpha.set_description(\"alpha: %i, Step4: Update Policy\" % e,refresh=True)\n",
    "    tqdm_epoch = trange(epochs, position=0, desc='Epochs', leave=True)\n",
    "    for i in  tqdm_epoch:\n",
    "        dataset=DS_Policy(traj_policy)\n",
    "        train_loader, validation_loader = train_valid_loader(dataset, batch_size=32, \n",
    "                                                             validation_split=0.3,\n",
    "                                                             shuffle_dataset=True)\n",
    "        \n",
    "        ls_ep = train_NN(train_loader, NN = 'pred')\n",
    "        ls_val_ep = validate_NN(validation_loader, NN = 'pred')\n",
    "        \n",
    "        tqdm_epoch.set_description(\"Policy Update - Epoch: %i, val loss: %.3f\" % (i,ls_val_ep),refresh=True)\n",
    "        \n",
    "        if ls_val_ep < ls_val_best:\n",
    "            ls_val_best = ls_val_ep\n",
    "            patience_cnt = 0\n",
    "    \n",
    "        else:\n",
    "            patience_cnt += 1\n",
    "            if patience_cnt == patience:\n",
    "#                 print(\"break\")\n",
    "                break\n",
    "\n",
    "    # step5, save model\n",
    "    if ls_val_ep < policy_best:\n",
    "        policy_best = ls_val_ep\n",
    "        policy_patience_cnt = 0\n",
    "        T.save(model.state_dict(), 'Model/model_ant_best.pt')\n",
    "\n",
    "    else:\n",
    "        policy_patience_cnt += 1\n",
    "    \n",
    "    if policy_patience_cnt==5:\n",
    "        break\n",
    "        \n",
    "    M *= DECAY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ipre = np.asarray(trajs_inv, dtype=object)\n",
    "# np.save('PreDemo_Interactions_Ant_5Lakh.npy', Ipre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# T.save(model.state_dict(), 'Model/model_test_ant_ID_train_%d.pt' % (e+1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "reward = 0\n",
    "reward_per_obs=np.array([])\n",
    "episodes = 20\n",
    "tqdm_episodes = trange(episodes, position=0, desc='Episode', leave=True)\n",
    "\n",
    "# model = BCO(env, policy=POLICY).cuda()\n",
    "# model.load_state_dict(torch.load('Model/model_ant_1.pt'))\n",
    "\n",
    "for i_episode in tqdm_episodes:\n",
    "    observation = env.reset()\n",
    "    rews=0\n",
    "    t=0\n",
    "    while True:\n",
    "        inp = T.from_numpy(observation).view(((1, )+observation.shape)).float().cuda()\n",
    "        out = model.pred_act(inp).cpu().detach().numpy()\n",
    "        act = out  ## Take actions predicted by the inverse dynamics model\n",
    "#         env.render()\n",
    "        observation, reward, done, info = env.step(act)\n",
    "        rews+=reward\n",
    "        t+=1\n",
    "        tqdm_episodes.set_description(\"Episode: %i, Step: %i\" % (i_episode+1,t),refresh=True)\n",
    "\n",
    "        if done:\n",
    "#             print(\"Episode finished after {} timesteps\".format(t+1))\n",
    "            print(rews)\n",
    "            reward_per_obs=np.append(reward_per_obs,rews)\n",
    "            break\n",
    "print(np.mean(reward_per_obs))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episode: 1, Step: 24:   0%|          | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating window glfw\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episode: 2, Step: 17:   5%|▌         | 1/20 [00:11<03:37, 11.43s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4603.344860457913\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episode: 3, Step: 17:  10%|█         | 2/20 [00:56<09:22, 31.27s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4664.65762974676\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episode: 4, Step: 16:  15%|█▌        | 3/20 [01:08<06:18, 22.29s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4627.632354215873\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episode: 5, Step: 17:  20%|██        | 4/20 [01:20<04:49, 18.11s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4852.233651763291\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episode: 5, Step: 920:  20%|██        | 4/20 [01:30<06:02, 22.65s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You can access the simulator by self.sim\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'ipdb'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-ecb3cbd6421d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_x\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpred_act\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mact\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mout\u001b[0m  \u001b[0;31m## Take actions predicted by the inverse dynamics model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m         \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrender\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m         \u001b[0mobservation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mact\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0mrews\u001b[0m\u001b[0;34m+=\u001b[0m\u001b[0mreward\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/gym/core.py\u001b[0m in \u001b[0;36mrender\u001b[0;34m(self, mode, **kwargs)\u001b[0m\n\u001b[1;32m    238\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrender\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'human'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 240\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrender\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    241\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    242\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/gym/envs/mujoco/mujoco_env.py\u001b[0m in \u001b[0;36mrender\u001b[0;34m(self, mode, width, height, camera_id, camera_name)\u001b[0m\n\u001b[1;32m    158\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'human'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 160\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_viewer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrender\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/mujoco_py/mjviewer.py\u001b[0m in \u001b[0;36mrender\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    204\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_loop_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_loop_count\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 206\u001b[0;31m                 \u001b[0mrender_inner_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    207\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_loop_count\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m         \u001b[0;31m# Markers and overlay are regenerated in every pass.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/mujoco_py/mjviewer.py\u001b[0m in \u001b[0;36mrender_inner_loop\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    180\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_overlay\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_full_overlay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 182\u001b[0;31m             \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrender\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    183\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_record_video\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m                 \u001b[0mframe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_read_pixels_as_in_window\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/mujoco_py/mjviewer.py\u001b[0m in \u001b[0;36mrender\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     58\u001b[0m             \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrender\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m         \u001b[0mglfw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoll_events\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mkey_callback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwindow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscancode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmods\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/glfw/__init__.py\u001b[0m in \u001b[0;36mpoll_events\u001b[0;34m()\u001b[0m\n\u001b[1;32m   1770\u001b[0m         \u001b[0mvoid\u001b[0m \u001b[0mglfwPollEvents\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvoid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1771\u001b[0m     \"\"\"\n\u001b[0;32m-> 1772\u001b[0;31m     \u001b[0m_glfw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglfwPollEvents\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1773\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1774\u001b[0m \u001b[0m_glfw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglfwWaitEvents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrestype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/glfw/__init__.py\u001b[0m in \u001b[0;36merrcheck\u001b[0;34m(result, *args)\u001b[0m\n\u001b[1;32m    630\u001b[0m             \u001b[0mexc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_exc_info_from_callback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    631\u001b[0m             \u001b[0m_exc_info_from_callback\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 632\u001b[0;31m             \u001b[0m_reraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    633\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    634\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/glfw/__init__.py\u001b[0m in \u001b[0;36m_reraise\u001b[0;34m(exception, traceback)\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0m_to_char_p\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_reraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexception\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraceback\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mexception\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraceback\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m     \u001b[0m_to_char_p\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/glfw/__init__.py\u001b[0m in \u001b[0;36mcallback_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    609\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    610\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 611\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    612\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSystemExit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    613\u001b[0m             \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/mujoco_py/mjviewer.py\u001b[0m in \u001b[0;36mkey_callback\u001b[0;34m(self, window, key, scancode, action, mods)\u001b[0m\n\u001b[1;32m    333\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mglfw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mKEY_I\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# drops in debugger.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'You can access the simulator by self.sim'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 335\u001b[0;31m             \u001b[0;32mimport\u001b[0m \u001b[0mipdb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    336\u001b[0m             \u001b[0mipdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    337\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mglfw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mKEY_S\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Slows down simulation.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'ipdb'"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "reward = 0\n",
    "reward_per_obs=np.array([])\n",
    "episodes = 20\n",
    "tqdm_episodes = trange(episodes, position=0, desc='Episode', leave=True)\n",
    "\n",
    "model_x = BCO(env, policy=POLICY).cuda()\n",
    "model_x.load_state_dict(torch.load('Model/model_ant_best_15.pt'))\n",
    "\n",
    "for i_episode in tqdm_episodes:\n",
    "    observation = env.reset()\n",
    "    rews=0\n",
    "    t=0\n",
    "    while True:\n",
    "        inp = T.from_numpy(observation).view(((1, )+observation.shape)).float().cuda()\n",
    "        out = model_x.pred_act(inp).cpu().detach().numpy()\n",
    "        act = out  ## Take actions predicted by the inverse dynamics model\n",
    "        env.render()\n",
    "        observation, reward, done, info = env.step(act)\n",
    "        rews+=reward\n",
    "        t+=1\n",
    "        tqdm_episodes.set_description(\"Episode: %i, Step: %i\" % (i_episode+1,t),refresh=True)\n",
    "\n",
    "        if done:\n",
    "#             print(\"Episode finished after {} timesteps\".format(t+1))\n",
    "            print(rews)\n",
    "            reward_per_obs=np.append(reward_per_obs,rews)\n",
    "            break\n",
    "print(np.mean(reward_per_obs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(val_loss_pol)\n",
    "print(\"hello\")\n",
    "print(train_loss_pol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(val_loss_id,'r')\n",
    "plt.plot(train_loss_id)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(val_loss_pol,'r')\n",
    "plt.plot(train_loss_pol)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
